# Copy this file to .env and fill in your API key.
# The application reads these values from environment variables.

# DeepSeek API key (required for LLM-powered analysis)
OPENAI_API_KEY=sk-your-deepseek-key-here

# DeepSeek API base URL (default, change for other providers)
OPENAI_BASE_URL=https://api.deepseek.com

# Model name used for text-based analysis (default: deepseek-chat)
OPENAI_MODEL=deepseek-chat

# Vision model used for direct image analysis.
# When set, the vision model reads text embedded in the meme AND analyses it
# for harmful content in a single API call â€” bypassing local OCR entirely.
# This is the approach used by most harmful-meme detection platforms and is
# strongly recommended when memes contain text that local OCR fails to read
# (e.g. low-contrast text on neutral/beige/white backgrounds).
#   - OpenAI:   gpt-4o  (set OPENAI_BASE_URL to https://api.openai.com/v1)
#   - DeepSeek: deepseek-vl2
# When not set, the pipeline attempts EasyOCR (local, no API call).
# If OCR still returns nothing but a text region is detected, the system
# automatically retries with OPENAI_MODEL as a vision fallback (works when
# OPENAI_MODEL is vision-capable, e.g. gpt-4o; fails gracefully otherwise).
# OPENAI_VISION_MODEL=gpt-4o

# Flask secret key (change in production)
# SECRET_KEY=change-me-in-production
